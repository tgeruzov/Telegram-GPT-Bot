import os
import sqlite3
import logging
from datetime import datetime, timezone
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    CommandHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
from openai import OpenAI
import asyncio
import random
import re

load_dotenv()

TG_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
DB_FILE = os.getenv("DB_PATH", "chat_history.db")
MAX_MSGS = int(os.getenv("MAX_HISTORY_MESSAGES", "12"))
MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", "512"))
CONCURRENCY = int(os.getenv("REQUEST_SEMAPHORE_LIMIT", "4"))
DEFAULT_HUMANIZE_LEVEL = int(os.getenv("HUMANIZE_LEVEL", "1"))

SYSTEM_PROMPT = os.getenv("SYSTEM_PROMPT"). –î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –±–∞–≥–∞: 1) –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ –ø—Ä–æ–±–ª–µ–º—É, 2) –ø—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –ø—Ä–∏–º–µ—Ä–æ–º –∫–æ–¥–∞ (–ø–∞—Ç—á), 3) —É–∫–∞–∂–∏ –∫–∞–∫ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∏–ª–∏ —Ç–µ—Å—Ç-–∫–µ–π—Å. –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ: —Ä–∞–±–æ—Ç–∞ —Å SQLite –≤ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–º/–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏, —Å–µ–º–∞—Ñ–æ—Ä –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –≤—ã–∑–æ–≤—ã, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ API, –≤–æ–∑–º–æ–∂–Ω—ã–µ None, –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ —á–∞–Ω–∫–∏, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ reply_markup, —É—Ç–µ—á–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ —Ä–µ—Å—É—Ä—Å–Ω—ã–µ –æ—à–∏–±–∫–∏. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –¥–∞–≤–∞–π –º–∏–Ω–∏–º—É–º —à—É–º–∞."
)


logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")
log = logging.getLogger(__name__)

client = OpenAI(api_key=OPENAI_KEY)

conn = sqlite3.connect(DB_FILE, check_same_thread=False)
cur = conn.cursor()
cur.execute(
    """
CREATE TABLE IF NOT EXISTS history (
    chat_id INTEGER,
    role TEXT,
    content TEXT,
    ts TEXT
)
"""
)
conn.commit()

semaphore = asyncio.Semaphore(CONCURRENCY)

chat_settings: dict[int, dict] = {}


def get_chat_setting(chat_id: int, key: str, default=None):
    s = chat_settings.get(chat_id)
    if not s:
        return default
    return s.get(key, default)


def set_chat_setting(chat_id: int, key: str, value):
    if chat_id not in chat_settings:
        chat_settings[chat_id] = {}
    chat_settings[chat_id][key] = value


def get_history(chat_id: int):
    rows = cur.execute(
        "SELECT role, content FROM history WHERE chat_id=? ORDER BY ts ASC",
        (chat_id,),
    ).fetchall()
    if len(rows) > MAX_MSGS:
        rows = rows[-MAX_MSGS:]
    return [{"role": r[0], "content": r[1]} for r in rows]


def save(chat_id: int, role: str, content: str):
    cur.execute(
        "INSERT INTO history (chat_id, role, content, ts) VALUES (?, ?, ?, ?)",
        (chat_id, role, content, datetime.now(timezone.utc).isoformat()),
    )
    conn.commit()


def create_control_kb(chat_id: int):
    level = get_chat_setting(chat_id, "humanize", DEFAULT_HUMANIZE_LEVEL)
    kb = InlineKeyboardMarkup(
        [
            [
                InlineKeyboardButton("–ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å", callback_data="clear"),
                InlineKeyboardButton("–ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", callback_data="regenerate"),
            ],
            [
                InlineKeyboardButton("–£–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π", callback_data="delete_last"),
                InlineKeyboardButton(f"–°—Ç–∏–ª—å: {level}", callback_data="toggle_humanize"),
            ],
        ]
    )
    return kb


async def send_with_control_buttons(update: Update, text: str):
    cid = update.effective_chat.id
    kb = create_control_kb(cid)
    if update.message:
        await update.message.reply_text(text, reply_markup=kb)
    else:
        await update.effective_chat.send_message(text, reply_markup=kb)


async def cmd_start(update: Update, _: ContextTypes.DEFAULT_TYPE):
    cid = update.effective_chat.id
    cur.execute("DELETE FROM history WHERE chat_id=?", (cid,))
    conn.commit()
    set_chat_setting(cid, "humanize", DEFAULT_HUMANIZE_LEVEL)
    await send_with_control_buttons(update, "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –Ø –≥–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å.")


async def cmd_help(update: Update, _: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç ‚Äî —è –µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞—é –º–æ–¥–µ–ª—å—é.\n"
        "/start ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∏–ª—å.\n\n"
        "–ö–Ω–æ–ø–∫–∏ –ø–æ–¥ –æ—Ç–≤–µ—Ç–æ–º: –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –£–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π, –°—Ç–∏–ª—å."
    )


async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    cid = q.message.chat.id
    data = q.data

    if data == "clear":
        cur.execute("DELETE FROM history WHERE chat_id=?", (cid,))
        conn.commit()
        await context.bot.send_message(cid, "–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")
        set_chat_setting(cid, "humanize", DEFAULT_HUMANIZE_LEVEL)
        await context.bot.send_message(cid, f"–°—Ç–∏–ª—å —Å–±—Ä–æ—à–µ–Ω –Ω–∞ {DEFAULT_HUMANIZE_LEVEL}.")
        return

    if data == "delete_last":
        row = cur.execute(
            "SELECT rowid FROM history WHERE chat_id=? AND role='assistant' ORDER BY ts DESC LIMIT 1",
            (cid,),
        ).fetchone()
        if not row:
            await context.bot.send_message(cid, "–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
            return
        cur.execute("DELETE FROM history WHERE rowid=?", (row[0],))
        conn.commit()
        await context.bot.send_message(cid, "–ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —É–¥–∞–ª—ë–Ω –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.")
        return

    if data == "regenerate":
        user_row = cur.execute(
            "SELECT content FROM history WHERE chat_id=? AND role='user' ORDER BY ts DESC LIMIT 1",
            (cid,),
        ).fetchone()
        if not user_row:
            await context.bot.send_message(cid, "–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
            return
        last_user_text = user_row[0]

        last_assistant = cur.execute(
            "SELECT rowid FROM history WHERE chat_id=? AND role='assistant' ORDER BY ts DESC LIMIT 1",
            (cid,),
        ).fetchone()
        if last_assistant:
            cur.execute("DELETE FROM history WHERE rowid=?", (last_assistant[0],))
            conn.commit()

        await context.bot.send_message(cid, "–ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

        system_prompt = SYSTEM_PROMPT
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(get_history(cid))
        if not any(m.get("role") == "user" and m.get("content") == last_user_text for m in messages):
            messages.append({"role": "user", "content": last_user_text})

        try:
            async with semaphore:
                reply = await call_model(messages)
        except Exception as e:
            log.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: %s", e)
            await context.bot.send_message(cid, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            return

        if isinstance(reply, str) and reply.startswith("__api_error__:"):
            err_text = reply.split(":", 1)[1]
            log.error("Model API error: %s", err_text)
            await context.bot.send_message(cid, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥–∞—Ö.")
            return

        if not isinstance(reply, str):
            reply = str(reply)

        if not reply.strip():
            reply = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."

        level = get_chat_setting(cid, "humanize", DEFAULT_HUMANIZE_LEVEL)
        try:
            humanized = humanize_reply(reply, level)
        except Exception:
            humanized = reply

        save(cid, "assistant", humanized)

        kb = create_control_kb(cid)
        CHUNK = 3900
        first = True
        for i in range(0, len(humanized), CHUNK):
            part = humanized[i : i + CHUNK]
            if first:
                await context.bot.send_message(cid, part, reply_markup=kb)
                first = False
            else:
                await context.bot.send_message(cid, part)
        return

    if data == "toggle_humanize":
        cur_level = get_chat_setting(cid, "humanize", DEFAULT_HUMANIZE_LEVEL)
        new_level = (cur_level + 1) % 3
        set_chat_setting(cid, "humanize", new_level)
        await context.bot.send_message(cid, f"–°—Ç–∏–ª—å –∏–∑–º–µ–Ω—ë–Ω: {new_level}")
        try:
            kb = create_control_kb(cid)
            await q.message.edit_reply_markup(reply_markup=kb)
        except Exception:
            pass
        return

    await context.bot.send_message(cid, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞.")


async def call_model(messages):
    loop = asyncio.get_running_loop()

    def api_call():
        try:
            resp = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=0.7,
            )
            try:
                return resp.choices[0].message.content
            except Exception:
                pass
            try:
                return resp["choices"][0]["message"]["content"]
            except Exception:
                pass
            return str(resp)
        except Exception as e:
            return f"__api_error__:{e}"

    return await loop.run_in_executor(None, api_call)


def _replace_formal_phrases(text: str) -> str:
    replacements = {
        r"\b–≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å\b": "–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ",
        r"\b–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ\b": "–Ω—É–∂–Ω–æ",
        r"\b–≤–æ–∑–º–æ–∂–Ω–æ\b": "–º–æ–∂–µ—Ç",
        r"\b–≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤\b": "—á–∞—â–µ –≤—Å–µ–≥–æ",
        r"\b—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ\b": "–≤—Å—ë –∂–µ",
        r"\b–≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏\b": "–µ—Å–ª–∏",
    }
    for pat, repl in replacements.items():
        text = re.sub(pat, repl, text, flags=re.IGNORECASE)
    return text


def _remove_ai_phrases(text: str) -> str:
    patterns = [
        r"–Ø (–∫–∞–∫|—è–≤–ª—è—é—Å—å) (–º–æ–¥–µ–ª—å—é|–º–æ–¥–µ–ª—å—é –ò–ò|–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º|–ò–ò)\b\.?",
        r"–ö–∞–∫ (–º–æ–¥–µ–ª—å|–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç|–ò–ò)[\.,]?",
        r"–Ø –Ω–µ –º–æ–≥—É –≤—ã–ø–æ–ª–Ω—è—Ç—å|–Ø –Ω–µ –º–æ–≥—É –ø–æ–º–æ—á—å —Å",
        r"–ö–∞–∫ (—è|–º–Ω–µ) –∏–∑–≤–µ—Å—Ç–Ω–æ[,]?",
    ]
    for p in patterns:
        text = re.sub(p, "", text, flags=re.IGNORECASE)
    return text.strip()


def _split_sentences(text: str):
    parts = re.split(r'(?<=[.!?])\s+', text.strip())
    return [p.strip() for p in parts if p.strip()]


def _maybe_insert_filler(sentences, level):
    if not sentences:
        return sentences
    fillers_easy = ["–ö—Å—Ç–∞—Ç–∏,", "–•–º,", "–ü–æ–∂–∞–ª—É–π,", ""]
    fillers_hard = ["–ï—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ,", "–í –¥–≤—É—Ö —Å–ª–æ–≤–∞—Ö,", "–ß–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä—è,", "–í–æ—Ç —á—Ç–æ —è –¥—É–º–∞—é:"]
    if level == 1 and random.random() < 0.25:
        f = random.choice(fillers_easy)
        if f:
            sentences[0] = f + " " + sentences[0]
    if level >= 2 and random.random() < 0.5:
        sentences[0] = random.choice(fillers_hard) + " " + sentences[0]
    return sentences


def _avoid_excessive_formality(text: str, level: int) -> str:
    text = _replace_formal_phrases(text)
    text = _remove_ai_phrases(text)
    text = text.replace("‚Äî", ",").replace("‚Äì", ",")
    sents = _split_sentences(text)
    sents = _maybe_insert_filler(sents, level)
    if level >= 2:
        for i, s in enumerate(sents):
            if len(s) > 280 and "," in s:
                parts = s.split(",", 1)
                sents[i] = parts[0].strip() + "."
                sents.insert(i + 1, parts[1].strip())
    out = " ".join(sents)
    if level >= 1 and random.random() < 0.18:
        out = out.rstrip() + " üëç"
    out = re.sub(r"\s{2,}", " ", out).strip()
    return out


def humanize_reply(text: str, level: int = 1) -> str:
    if not text:
        return text
    text = text.strip()
    text = re.sub(r"^(Assistant:|AI:)\s*", "", text, flags=re.IGNORECASE)
    text = _avoid_excessive_formality(text, level)
    text = re.sub(r"\.{3,}", "‚Ä¶", text)
    if level >= 2 and random.random() < 0.12:
        text = re.sub(r"\b–¥–∞–≤–∞–π—Ç–µ\b", "–¥–∞–≤–∞–π", text, flags=re.IGNORECASE)
    return text


async def on_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    cid = update.effective_chat.id
    user_text = update.message.text.strip()
    save(cid, "user", user_text)

    system_prompt = SYSTEM_PROMPT
    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(get_history(cid))

    await update.message.chat.send_action("typing")

    try:
        async with semaphore:
            reply = await call_model(messages)
    except Exception as e:
        log.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: %s", e)
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    if isinstance(reply, str) and reply.startswith("__api_error__:"):
        err_text = reply.split(":", 1)[1]
        log.error("Model API error: %s", err_text)
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥–∞—Ö.")
        return

    if not isinstance(reply, str):
        reply = str(reply)

    if not reply.strip():
        reply = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."

    level = get_chat_setting(cid, "humanize", DEFAULT_HUMANIZE_LEVEL)
    try:
        humanized = humanize_reply(reply, level)
    except Exception:
        humanized = reply

    save(cid, "assistant", humanized)

    CHUNK = 3900
    kb = create_control_kb(cid)
    first = True
    for i in range(0, len(humanized), CHUNK):
        part = humanized[i : i + CHUNK]
        if first:
            await update.message.reply_text(part, reply_markup=kb)
            first = False
        else:
            await update.message.reply_text(part)


def main():
    if not TG_TOKEN:
        log.error("TELEGRAM_TOKEN –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env")
        return

    if not SYSTEM_PROMPT:
        log.error("SYSTEM_PROMPT –Ω–µ –∑–∞–¥–∞–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ SYSTEM_PROMPT –≤ .env")
        return

    app = ApplicationBuilder().token(TG_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("help", cmd_help))
    app.add_handler(CallbackQueryHandler(on_callback))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_message))

    log.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    app.run_polling()


if __name__ == "__main__":
    main()
